# Whisper Server Prototype

Simple Flask service that accepts a small audio upload and returns a transcription
generated by the `small.en` Whisper model running locally on CPU.

## Setup

```bash
cd whisper_server
python3.12 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

The first transcription triggers a one-time download of the Whisper weights into
`./models`. Use `WHISPER_MODEL_DIR` to override the cache location.

## Running the server

```bash
FLASK_APP=app.py flask run --host=0.0.0.0 --port=5000
# or
python app.py
```

Environment variables:

- `WHISPER_MODEL_SIZE` (default `small.en`)
- `MAX_UPLOAD_MB` (default `10`)

## CLI usage

Run the CLI for quick offline transcriptions:

```bash
python transcribe_cli.py sample.aac
# or to see the JSON payload
python transcribe_cli.py sample.aac --json
```

## Example request

```bash
curl -X POST http://localhost:5000/transcribe \
  -F "file=@/path/to/snippet.wav"
```

Response:

```json
{
  "text": "Hello world",
  "detected_language": "en",
  "duration": 1.23,
  "segments": [
    {"start": 0.0, "end": 1.23, "text": " Hello world"}
  ]
}
```
